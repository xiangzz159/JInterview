
- [线程基础](#线程基础)
  - [线程的概念、好处、难处](#线程的概念好处难处)
  - [创建、启动和终止线程](#创建启动和终止线程)
    - [创建与启动](#创建与启动)
    - [线程的停止](#线程的停止)
  - [线程的状态、优先级、demon线程](#线程的状态优先级demon线程)
    - [线程的状态](#线程的状态)
    - [线程的优先级](#线程的优先级)
    - [demon线程（守护线程）](#demon线程守护线程)
  - [线程中常用方法辨析](#线程中常用方法辨析)
  - [线程间的协作/通信](#线程间的协作通信)
    - [等待/通知机制](#等待通知机制)
    - [ReentrantLock类加锁](#reentrantlock类加锁)
    - [通过管道进行线程间通信：字节流/字符流](#通过管道进行线程间通信字节流字符流)
  - [线程应用实例](#线程应用实例)
  - [并发编程的风险与挑战](#并发编程的风险与挑战)
    - [一、优点](#一优点)
    - [二、缺点](#二缺点)
    - [三、挑战](#三挑战)
- [原子操作类解析](#原子操作类解析)
  - [什么是CAS？](#什么是cas)
  - [CAS的问题](#cas的问题)
  - [原子操作的实现原理解析](#原子操作的实现原理解析)
  - [原子操作类的使用](#原子操作类的使用)
- [Lock、Condition和AQS分析](#lockcondition和aqs分析)
  - [Lock](#lock)
  - [Condition](#condition)
  - [AQS(AbstractQueuedSynchronizer)](#aqsabstractqueuedsynchronizer)
- [并发工具和并发容器](#并发工具和并发容器)
  - [容器](#容器)
    - [ConcurrentHashMap](#concurrenthashmap)
      - [为什么要使用ConcurrentHashMap](#为什么要使用concurrenthashmap)
      - [实现原理](#实现原理)
    - [其他并发容器](#其他并发容器)
    - [阻塞队列应用与原理](#阻塞队列应用与原理)
  - [Fork/Join概念与应用](#forkjoin概念与应用)
    - [ForkJoinTask](#forkjointask)
    - [ForkJoinPool](#forkjoinpool)
    - [Fork/Join框架的实现原理](#forkjoin框架的实现原理)
  - [并发工具类](#并发工具类)
    - [CountDownLatch](#countdownlatch)
    - [CyclicBarrier](#cyclicbarrier)
    - [Semaphore](#semaphore)
    - [Exchange](#exchange)
- [线程池和Executor框架](#线程池和executor框架)
  - [什么是线程池](#什么是线程池)
  - [为什么要使用线程池](#为什么要使用线程池)
  - [线程池的优点](#线程池的优点)
  - [线程池ThreadPoolExecutor原理与应用](#线程池threadpoolexecutor原理与应用)
    - [线程池的创建和线程池的基本设置：（6个参数）](#线程池的创建和线程池的基本设置6个参数)
    - [向线程池提交任务](#向线程池提交任务)
  - [Executor框架](#executor框架)


# 线程基础
## 线程的概念、好处、难处
一个程序就是一个进程，而一个程序中的多个任务则被称为线程。

进程是表示资源分配的基本单位，线程是进程中执行运算的最小单位，亦是调度运行的基本单位。
|区别|进程|线程|
|:--|:--|:--|
|根本区别|作为资源分配的单位|调度和执行的单位|
|开销|每个进程都有独立的代码和数据空间（进程上下文），进程间的切换会有较大的开销|线程可以看成是轻量级的进程，同一类线程共享代码和数据空间，每个线程有独立的运行栈和程序计数器，线程切换的开销小|
|所处环境|在操作系统中能同时运行多个任务|在同一个程序中有多个顺序流同时执行|
|分配内存|系统在运行的时候会为每个进程分配不同的内存区域|除了CPU之外，不会为线程分配内存（线程所使用的资源是他所属的进程的资源），线程组只能共享资源|
|包含关系|没有线程的进程是可以被看作单线程的，如果一个进程内拥有多个线程，则执行过程不是一条线的，而是多条线共同完成的|线程是进程的一部分，所以线程有的时候被称为是轻量级进程或者轻权进程|

优点：
- 提高资源利用率
- 程序设计在某些情况下更简单
- 程序响应更快

缺点：
- 设计更复杂，虽然有一些多线程应用程序比单线程的饮用程序要简单，但其他的一般都更复杂。在多线程访问共享数据的时候，这部分代码需要特别注意。线程之间的交互往往非常复杂。不正确的线程同步产生的错误非常难以被发现。
- 上下文切换的开销，当CPU从执行一个线程切换到执行另一个线程的时候，它需要先存储当前线程的本地数据，程序、指针等，然后载入另一个线程的本地数据，程序指针等，最后才开始执行。这种切换称为“上下文切换”。CPU会在一个上下文中执行一个线程，然后切换到另一个上下文中执行另一个线程。上下文切换并不廉价。如果没有必要，应该减少上下文切换的发生。

## 创建、启动和终止线程
### 创建与启动
- 实现Runnable接口，重写run()
  ```java
  public class MyRunnable implements Runnable {
      public void run() {
          System.out.println("MyRunnable");
      }

      public static void main(String[] args) {
          MyRunnable myRunnable = new MyRunnable();
          Thread thread = new Thread(myRunnable);
          thread.start();
          System.out.println("End!");
      }
  }
  ```
- 继承Thread类，重写run()
  ```java
  public class MyThread extends Thread {
      @Override
      public void run() {
          super.run();
          System.out.println("MyThread");
      }

      public static void main(String[] args) {
          MyThread myThread = new MyThread();
          myThread.start();
          System.out.println("运行结束！");
      }
  }
  ```
- 实现Callable接口，重写call()，利用FutureTask包装Callable，并作为task传入Thread构造函数
  ```java
  public class MyCallable implements Callable<Long> {
      public Long call() throws Exception {
          Long nowTime = System.currentTimeMillis();
          return nowTime;
      }

      public static void main(String[] args) {
          MyCallable myCallable = new MyCallable();
          //1.执行 Callable 方式，需要 FutureTask 实现类的支持，用于接收运算结果。

          FutureTask<Long> ft = new FutureTask<Long>(myCallable);
          new Thread(ft).start();
          //2.接收线程运算后的结果
          try {
              Long nowTime = ft.get();  //FutureTask 可用于 闭锁 类似于CountDownLatch的作用，在所有的线程没有执行完成之后这里是不会执行的
              System.out.println(nowTime);
              System.out.println("------------------------------------");
          } catch (Exception e) {
              e.printStackTrace();
          }
      }
  }
  ```

|实现Runnable接口|继承Thread类|实现Callable接口|
|:--|:--|:--|
|只需要实现接口，不影响正常代码结构，可以通过匿名内部类的方式实现，开发简单|Java是单根继承，通过这个方法实现多线程无法继承其他父类|和Runnable的区别是有返回值|

### 线程的停止
- 通过标示位终止线程
  ```java
  public class ServerThread extends Thread {
      //volatile修饰符用来保证其它线程读取的总是该变量的最新的值
      public volatile boolean exit = false; 

      @Override
      public void run() {
          ServerSocket serverSocket = new ServerSocket(8080);
          while(!exit){
              serverSocket.accept(); //阻塞等待客户端消息
              ...
          }
      }
      
      public static void main(String[] args) {
          ServerThread t = new ServerThread();
          t.start();
          ...
          t.exit = true; //修改标志位，退出线程
      }
  }
  ```
- 通过stop()终止线程（已弃用）
  - 调用 stop() 方法会立刻停止 run() 方法中剩余的全部工作，包括在 catch 或 finally 语句中的，并抛出ThreadDeath异常(通常情况下此异常不需要显示的捕获)，因此可能会导致一些清理性的工作的得不到完成，如文件，数据库等的关闭。
  - 调用 stop() 方法会立即释放该线程所持有的所有的锁，导致数据得不到同步，出现数据不一致的问题。

- 使用interrupt() 中断线程:这个方法并不会停止正在运行中的线程，还需要加入一个判断才可以完成线程的停止
  ```java
  public class StopThread2 extends Thread {
      @Override
      public void run() {
          super.run();
          for (int i=0; i<500000; i++) {
              if (this.isInterrupted()) {
                  System.out.println("已经停止状态了，我要退出了！");
                  break;
              }
              System.out.println("i=" + (i + 1));
          }
          System.out.println("我被输出，如果此代码是for循环又继续运行，线程并未停止！");
      }

      public static void main(String[] args) {
          try {
              StopThread2 stopThread2 = new StopThread2();
              stopThread2.start();
              Thread.sleep(200);
              stopThread2.interrupt();
          } catch (Exception e) {
              System.out.println("main catch");
              e.printStackTrace();
          }
          System.out.println("End!");
      }
  }
  ```
## 线程的状态、优先级、demon线程
### 线程的状态
Java中线程周期可分为5种状态
- 新建：新创建一个线程
- 就绪：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取cpu的使用权。
- 阻塞：阻塞状态是指线程因为某种原因放弃了cpu使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu timeslice 转到运行(running)状态。阻塞的情况分三种：
  - 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。
  - 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。
  - 其他阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。
  
- 运行：可运行状态(runnable)的线程获得了cpu时间片（timeslice），执行程序代码。
- 死亡：线程run()、main()方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生。
  
![img](./img/PerformanceTuning.png)

### 线程的优先级
在操作系统中，线程是可以划分优先级，优先级较高的线程得到的CPU资源较多，也就是CPU优先执行优先级较高的线程对象中的任务。

在Java中，优先级分为1～10这10个等级，通过setPriority()方法设置，如果小于1或者大于10，则JDK抛出IllegalArgumentException()异常

线程优先级具有以下几个特性：
- 继承性：A线程启动B线程，则B线程的优先级和A一样
- 规则性：优先级高的线程总是大部分先执行完，CPU尽量将执行资源让给优先级比较高的线程，但不代表高优先级的线程全部先执行完。当线程优先级的等级差距很大时，谁先执行完和代码调用顺序无关。
- 随机性：优先级高的线程不一定都先执行完

### demon线程（守护线程）
一种特殊的线程，任何一个守护线程都是整个JVM中所有非守护线程的“保姆”，只要当前JVM实例中存在任何一个非守护线程没有结束，守护线程就在工作，只有当最后一个非守护线程结束时，守护线程才随着JVM一同结束工作。守护线程最典型的应用就是GC。

## 线程中常用方法辨析
![img](./img/WX20200923-141937@2x.png)

1. 新建一个新的线程对象后，在调用他的start()方法，系统会为此线程分配CPU资源，使其处于Runnable（可运行）状态，这是一个准备运行的阶段。如果线程抢占到CPU资源，此线程处于Running（运行）状态。
2. Runnable状态和Running状态可互相切换，因为有可能线程运行一段时间后，有其他高优先级的线程抢占了CPU资源，这时此线程就从Running状态变成Runnable状态  
线程进入Runnable状态大体分为如下5种情况：
  - 调用sleep()方法后经过的时间超过了指定的休眠时间
  - 线程调用的阻塞IO已经返回，阻塞方法执行完毕
  - 线程成功地获得了试图同步的监视器
  - 线程正在等待某个通知，其他线程发出了通知
  - 处于挂起状态的线程调用了resume恢复方法
3. Blocked是阻塞的意思，如果遇到了一个IO操作，此时CPU处于空闲状态，可能会转而吧CPU时间片分配给其他线程，这时也可以称为“暂停”状态。Blocked状态结束后，进入Runnable状态，等待系统重新分配资源  
出现阻塞的情况大体分为如下5种：
  - 阻塞调用sleep方法，主动放弃占用的处理器资源
  - 线程调用了阻塞式IO方法，在该方法返回前，该线程被阻塞
  - 线程试图获得一个同步监视器，但该同步监视器正被其他线程所持有
  - 线程等待某个通知
  - 程序调用suspend方法将该线程挂起。此方法容易导致死锁，尽量避免使用该方法。

4. run()方法运行结束后进入销毁阶段，整个线程执行完毕。

## 线程间的协作/通信
线程是操作系统中独立的个体，但这些个体如果不经过特殊的处理就不能成为一个整体。线程间的通信就是成为整体的必用方案之一，可以说，使线程间进行通信后，系统之间的交互性会更强大，在大大提高CPU利用率的同时还会使程序员对各线程任务在处理的过程中进行有效的把控与监督。
### 等待/通知机制
- wait():使当前执行代码的线程进行等待，将当前线程置入“预执行队列”中，并且在wait()所在的代码行处停止执行，直到接到通知或被中断为止。只能在同步方法或同步块中调用
- notify():在调用前，线程必须活动该对象的对象级别锁。该方法用来通知那些可能等待该对象的对象锁的其他线程，如果有多个线程等待，则由线程规划器随机挑选出其中一个呈wait状态的线程，对其发出通知notify，并使它等待获取该对象的对象锁。在执行notify()方法后，当前线程要退出synchronized代码块后才会释放锁。
- join():使所属的线程对象x正常执行run()方法中的任务，而使当前线程z进行无限制的阻塞，等待线程x销毁后再继续执行线程z后面的代码
- wait()、notify()、notifyAll()方法是本地方法，并且位final方法，无法被重写

### ReentrantLock类加锁
在JDK1.5中新增了ReentrantLock类能实现线程之间同步互斥的效果，并且在扩展功能上也更加强大，比如具有嗅探锁定、多路分支通知等功能，而且在使用上也比synchronized更加灵活。

关键字synchronized与wait()/notify()/notifyAll()方法结合可以实现等待/通知模式，类ReentrantLock可以通过借助Condition对象实现。Condition是在java 1.5中才出现的，它用来替代传统的Object的wait()、notify()实现线程间的协作，相比使用Object的wait()、notify()，使用Condition1的await()、signal()这种方式实现线程间协作更加安全和高效。因此通常来说比较推荐使用Condition，在阻塞队列那一篇博文中就讲述到了，阻塞队列实际上是使用了Condition来模拟线程间协作。
- Condition是个接口，基本的方法就是await()和signal()方法；
- Condition依赖于Lock接口，生成一个Condition的基本代码是lock.newCondition() 
- 调用Condition的await()和signal()方法，都必须在lock保护之内，就是说必须在lock.lock()和lock.unlock之间才可以使用

### 通过管道进行线程间通信：字节流/字符流
- PipedinputStream 和 PipedOutputStream
- PipedReader 和 PipedWriter

## 线程应用实例
参考：[multithreading](https://github.com/xiangzz159/JInterview-demo/tree/master/multithreading)

## 并发编程的风险与挑战
### 一、优点
- 速度优势：多处理器上面并发变成无疑会让程序运行很快。
- 设计上优势：线程使得你能够创建更加松耦合的设计。
### 二、缺点
- 安全性问题：主要是多个线程共享数据时可能会产生于期望不相符的结果。
- 活跃性问题(liveness)：当某个操作无法继续进行下去时，就会发生活跃性问题。比如死锁、饥饿、活锁等问题。
- 性能问题
  - 线程过多时会使得CPU频繁切换，花在调度上时间太多。
  - 多线程环境必须使用同步机制，导致很多编译器想做的优化被抑制。
  - 线程也需要占用内存，过多还会消耗过多内存。
### 三、挑战
- 减少上下文切换：减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。
- 避免死锁
- 资源限制

# 原子操作类解析
## 什么是CAS？
CAS是compare and swap的缩写，即我们所说的比较交换。cas是一种基于锁的操作，而且是乐观锁。在java中锁分为乐观锁和悲观锁。悲观锁是将资源锁住，等一个之前获得锁的线程释放锁之后，下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录加version来获取数据，性能较悲观锁有很大的提高。

CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存地址里面的值和A的值是一样的，那么就将内存里面的值更新成B。CAS是通过无限循环来获取数据的，若果在第一轮循环中，a线程获取地址里面的值被b线程修改了，那么a线程需要自旋，到下次循环才有可能机会执行。

## CAS的问题
1. CAS容易造成ABA问题。一个线程a将数值改成了b，接着又改成了a，此时CAS认为是没有变化，其实是已经变化过了，而这个问题的解决方案可以使用版本号标识，每操作一次version加1。在java5中，已经提供了AtomicStampedReference来解决问题。
2. CAS造成CPU利用率增加。之前说过了CAS里面是一个循环判断的过程，如果线程一直没有获取到状态，cpu资源会一直被占用。

## 原子操作的实现原理解析
AutoInteger的实现源码
```Java
public final int getAndIncrement() {
    return unsafe.getAndAddInt(this, valueOffset, 1);  //第一个参数当前对象地址，第二个参数数据偏移量，第三个参数每次指定默认加1
}
```

```Java
public final int getAndAddInt(Object var1, long var2, int var4) {  //这个方法使用的就是CAS,核心在于循环比较内存里面的值和当前值是否相等，如果相等就用新值覆盖
    int var5;   
    do {
        var5 = this.getIntVolatile(var1, var2);  //如果a，b线程同时执行这个方法，a线程拿到值1后cpu执行时间到了挂起，b开始执行，也拿到1，但是没有挂起，接着将值变成了2
    } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));  //这个时候a线程恢复执行，去比较的时候发现手上的1 和内存里面的值2不等，这个时候他要进行下一个循环，看出来了占用cpu吧
    return var5;
}
```
AtomicInteger，AtomicLong,AtomicBoolean.....都在java.util.current.atomic包下面，采用了CAS机制来实现加锁
## 原子操作类的使用
假设一个共享变量MyCount,开5个线程，每个线程加20次，不加锁的情况下，结果一般来说都会小于100.
```Java 
@Test
public void test20() throws InterruptedException {
    for (int i = 1; i <= 5; i++) {
        MyThrend thrend = new MyThrend("thead" + i);
        Thread thread = new Thread(thrend);
        thread.start();
    }
    Thread.sleep(2000);
    System.out.println(MyCount1.count);
}

static class MyThrend implements Runnable {
    private String name;
    MyThrend(String threadName) {
        this.name = threadName;
    }

    @Override
    public void run() {
        for (int i=0;i<20;i++)
        MyCount1.count++;
    }
}

private static class MyCount1 {
    static int count = 0;
}
```

修改int类型为AtomicInteger类型
```Java 
@Test
public void test20() throws InterruptedException {
    for (int i = 1; i <= 5; i++) {
        MyThrend thrend = new MyThrend("thead" + i);
        Thread thread = new Thread(thrend);
        thread.start();
    }
    Thread.sleep(2000);
    System.out.println(MyCount.count.get());
}

static class MyThrend implements Runnable {
    private String name;
    MyThrend(String threadName) {
        this.name = threadName;
    }

    @Override
    public void run() {
        for (int i=0;i<20;i++)
        MyCount.count.getAndIncrement();  //加1方法
    }
}

private static class MyCount {
    static AtomicInteger count = new AtomicInteger(0);
}
```

# Lock、Condition和AQS分析
## Lock
lock与sychronized都能达到相同的效果，保证线程的原子性，可见性，一致性。但是lock比sychronied更加灵活
1. lock是jdk层面上的实现，sychronized是jvm层面的关键字。
2. lock.lock()与lock.unlock()可以主动获取锁释放锁，sychronized是被动的释放锁  
   sychronized释放锁的时机：
   - 代码执行执行结束
   - 产生异常了  
3. lock可以判断锁的状态，sychronized是一个关键字，没法去判断锁的状态。
4. lock可以指定公平锁和非公平锁，sychronized只能作为非公平锁
5. lock可以有共享锁与排他锁，例如读写锁的实现。而sychronized是一个可重入的排他锁

总结： Lock的核心就是AQS队列，CAS算法，LockSupport中的park与unpark方法。
## Condition
Condition由Lock创建，是一对多关系

Condition是JUC里面提供的对锁的控制，condition的await()方法， 与condition的singinal()方法和Object中的wait()和notify()等价。

如果说Lock是为了扩展现有的监视器锁，那么Condition肯定就是对wait、notify的延伸了。

首先，我们调用wait方法的原因通常是线程有一定的条件不满足，我们才会去让其等待。其次，所有调用了wait方法的线程都会在同一个wait set中等待，嗯嗯这看上去很合理。

但这正式这一机制的短板之处，因为每一个wait的线程其实都是在等待同一个notify或notifyAll方法来唤醒自己，这就会导致自己可能会被别的线程的notify方法唤醒。

然而我们知道每个线程的执行条件肯定是不一样的，故会导致我虽然抢到资源取执行逻辑了，但却会发现自己依然不满足执行条件，然后就又wait了。

这无疑使一个浪费CPU资源的操作，所以说最好的方式就是每个线程知道自己在wait什么条件，这样notify的时候也不会唤醒别的线程，这就是Condition的做法。

## AQS(AbstractQueuedSynchronizer)
AbstractQuenedSynchronizer抽象的队列式同步器。是除了java自带的synchronized关键字之外的锁机制。
-  FIFO队列
-  提供独占锁和共享锁功能

如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并将共享资源设置为锁定状态，如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

CLH（Craig，Landin，and Hagersten）队列是一个虚拟的双向队列，虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系。

AQS是将每一条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node），来实现锁的分配。

总结：AQS就是基于CLH队列，用volatile修饰共享变量state，线程通过CAS去改变状态符，成功则获取锁成功，失败则进入等待队列，等待被唤醒。

> AQS是自旋锁：**在等待唤醒的时候，经常会使用自旋（while(!cas())）的方式，不停地尝试获取锁，直到被其他线程获取成功


# 并发工具和并发容器
## 容器
Java的集合容器框架中，主要有四大类别：List、Set、Queue、Map，大家熟知的这些集合类ArrayList、LinkedList、HashMap这些容器都是非线程安全的。

如果有多个线程并发地访问这些容器时，就会出现问题。因此，在编写程序时，在多线程环境下必须要求程序员手动地在任何访问到这些容器的地方进行同步处理，这样导致在使用这些容器的时候非常地不方便。

所以，Java先提供了同步容器供用户使用。

同步容器可以简单地理解为通过synchronized来实现同步的容器，比如Vector、Hashtable以及SynchronizedList等容器。

这些容器实现线程安全的方式就是将它们的状态封装起来，并在需要同步的方法上加上关键字synchronized。

这样做的代价是削弱了并发性，当多个线程共同竞争容器级的锁时，吞吐量就会降低。

因此为了解决同步容器的性能问题，所以才有了并发容器。

java.util.concurrent包中提供了多种并发类容器。

并发类容器是专门针对多线程并发设计的，使用了锁分段技术，只对操作的位置进行同步操作，但是其他没有操作的位置其他线程仍然可以访问，提高了程序的吞吐量。

采用了CAS算法和部分代码使用synchronized锁保证线程安全。

### ConcurrentHashMap
#### 为什么要使用ConcurrentHashMap
在多线程环境下，使用HashMap进行put操作会引起死循环，导致CPU利用率接近100%，HashMap在并发执行put操作时会引起死循环，是因为多线程会导致HashMap的Entry链表

形成环形数据结构，一旦形成环形数据结构，Entry的next节点永远不为空，就会产生死循环获取Entry。

HashTable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法，其他线程也访问HashTable的同步方法时，会进入阻塞或轮询状态。如线程1使用put进行元素添加，线程2不但不能使用put方法添加元素，也不能使用get方法来获取元素，所以竞争越激烈效率越低。
#### 实现原理
1.7以下使用分段锁-Segment
![img](./img/5220087-8c5b0cc951e61398.png)

ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构， 一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素， 每个Segment守护者一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。

计算ConcurrentHashMap的元素大小是一个有趣的问题，因为他是并发操作的，就是在你计算size的时候，他还在并发的插入数据，可能会导致你计算出来的size和你实际的size有相差（在你return size的时候，插入了多个数据），要解决这个问题，JDK1.7版本用两种方案
1. 第一种方案他会使用不加锁的模式去尝试多次计算ConcurrentHashMap的size，最多三次，比较前后两次计算的结果，结果一致就认为当前没有元素加入，计算的结果是准确的
2. 第二种方案是如果第一种方案不符合，他就会给每个Segment加上锁，然后计算ConcurrentHashMap的size返回


JDK1.8的实现已经抛弃了Segment分段锁机制，利用CAS+Synchronized来保证并发更新的安全。数据结构采用：Node数组+链表+红黑树。
![img](./img/5220087-63281d7b737f1109.png)

> ConcurrentHashMap的数据结构（数组+链表+红黑树），桶中的结构可能是链表，也可能是红黑树，红黑树是为了提高查找效率。

1.7 与 1.8 版本比较
1. JDK1.8的实现降低锁的粒度，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点）
2. JDK1.8版本的数据结构变得更加简单，使得操作也更加清晰流畅，因为已经使用synchronized来进行同步，所以不需要分段锁的概念，也就不需要Segment这种数据结构了，由于粒度的降低，实现的复杂度也增加了
3. JDK1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表，这样形成一个最佳拍档
4. JDK1.8为什么使用内置锁synchronized来代替重入锁ReentrantLock，我觉得有以下几点
   - 因为粒度降低了，在相对而言的低粒度加锁方式，synchronized并不比ReentrantLock差，在粗粒度加锁中ReentrantLock可能通过Condition来控制各个低粒度的边界，更加的灵活，而在低粒度中，Condition的优势就没有了
   - JVM的开发团队从来都没有放弃synchronized，而且基于JVM的synchronized优化空间更大，使用内嵌的关键字比使用API更加自然
   - 在大量的数据操作下，对于JVM的内存压力，基于API的ReentrantLock会开销更多的内存，虽然不是瓶颈，但是也是一个选择依据

### 其他并发容器
1. ConcurrentQueue：与ConcurrentHashMap相同，ConcurrentQueue也是通过同样的方式来提高并发性能的。
2. CopyOnWriteArrayList：写时复制容器，即copy-on-write,在多线程环境下，写时效率低，读时效率高，适合写少读多的环境。
3. BlockingQueue：这种并发容器，会自动实现阻塞式的生产者/消费者模式。使用队列解耦合，在实现异步事物的时候很有用。
4. ArrayBlockingQueue：对象的方法和上面的BlockingQueue是一样的，用法也是一样的。二者的区别主要是：
   - LinkedBlockingQueue是一个单向链表实现的阻塞队列，在链表一头加入元素，如果队列满，就会阻塞，另一头取出元素，如果队列为空，就会阻塞。
   - LinkedBlockingQueue内部使用ReentrantLock实现插入锁(putLock)和取出锁(takeLock)。
   - ArrayBlockingQueue是有界的，LinkedBlockingQueue是无界的
5. LinkedBlockingQueue：使用链表是实现的阻塞式容器
6. DelayQueue：DelayQueue是一个使用优先队列（PriorityQueue）实现的BlockingQueue，优先队列的比较基准值是时间。这是一个无界的BlockingQueue，用于放置实现了Delayed接口的对象，其中的对象只能在其到期时才能从队列中取走。这种队列是有序的，即队头对象的延迟到期时间最长。但是要注意的是，不能将null元素放置到这种队列中。
7. LinkedTransferQueue：LinkedTransferQueue是TransferQueue接口的实现类，其定义为一个无界的队列，具有先进先出(FIFO)的特性。
8. SynchronousQueue：SynchronousQueue也是一种BlockingQueue，是一种无缓冲的等待队列。所以，在某次添加元素后必须等待其他线程取走后才能继续添加；可以认为SynchronousQueue是一个缓存值为0的阻塞队列(也可以认为是1)，它的isEmpty()方法永远返回是true，remainingCapacity()方法永远返回是0.


### 阻塞队列应用与原理
阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。

JDK7提供了7个阻塞队列。分别是：
- ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。
- LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。
- PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。
- DelayQueue：一个使用优先级队列实现的无界阻塞队列。
- SynchronousQueue：一个不存储元素的阻塞队列。
- LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。
- LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。

## Fork/Join概念与应用
Fork/Join框架是Java 7提供的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。Fork/Join框架要完成两件事情：
- 任务分割：首先Fork/Join框架需要把大的任务分割成足够小的子任务，如果子任务比较大的话还要对子任务进行继续分割
- 执行任务并合并结果：分割的子任务分别放到双端队列里，然后几个启动线程分别从双端队列里获取任务执行。子任务执行完的结果都放在另外一个队列里，启动一个线程从队列里取数据，然后合并这些数据

### ForkJoinTask
使用Fork/Join框架，首先需要创建一个ForkJoin任务。该类提供了在任务中执行fork和join的机制。通常情况下我们不需要直接集成ForkJoinTask类，只需要继承它的子类，Fork/Join框架提供了两个子类:
- RecursiveAction:用于没有返回结果的任务
- RecursiveTask:用于有返回结果的任务
### ForkJoinPool
ForkJoinTask需要通过ForkJoinPool来执行。

任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列的头部。当一个工作线程的队列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务(工作窃取算法)；

### Fork/Join框架的实现原理
ForkJoinPool由ForkJoinTask数组和ForkJoinWorkerThread数组组成，ForkJoinTask数组负责将存放程序提交给ForkJoinPool，而ForkJoinWorkerThread负责执行这些任务;

``` Java
public class ForkJoinDemo1 {
    public static void main(String[] args) {
        ForkJoinPool pool = new ForkJoinPool();
        CountTask task = new CountTask(1,4);
        Future<Integer> result = pool.submit(task);
        try {
            System.out.println("计算结果=" + result.get());
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();
        }}}

class CountTask extends RecursiveTask<Integer> {
    private static final long serialVersionUID = -7524245439872879478L;
    private static final int THREAD_HOLD = 2;
    private int start;
    private int end;
    public CountTask(int start,int end){
        this.start = start;
        this.end = end;    }

    @Override
    protected Integer compute() {
        int sum = 0;
        //如果任务足够小就计算
        boolean canCompute = (end - start) <= THREAD_HOLD;
        if(canCompute){
            for(int i=start;i<=end;i++){
                sum += i;
            }
        }else{
            int middle = (start + end) / 2;
            CountTask left = new CountTask(start,middle);
            CountTask right = new CountTask(middle+1,end);
            //执行子任务
            left.fork();
            right.fork();
            //获取子任务结果
            int lResult = left.join();
            int rResult = right.join();
            sum = lResult + rResult;
        }
        return sum;}}
```

## 并发工具类
### CountDownLatch
CountDownLatch是一个同步计数器，初始化的时候 传入需要计数的线程等待数，可以是需要等待执行完成的线程数，或者大于。
作用：用来协调多个线程之间的同步，或者说起到线程之间的通信（而不是用作互斥的作用）。是一组线程等待其他的线程完成工作以后在执行，相当于加强版join，其中：
> await()：阻塞当前线程，等待其他线程执行完成，直到计数器计数值减到0。  
> countDown()：负责计数器的减一。

```Java
public class CountDownLatchDemo {
    // TODO 修改数量后看看效果
    private static CountDownLatch countDownLatch = new CountDownLatch(6);
    private static class InitThread extends Thread {
        @Override
        public void run() {
            System.out.println("InitThread线程" + Thread.currentThread().getName() + "开始初始化....");
            countDownLatch.countDown();}}
    private static class BusiThread extends Thread {
        @Override
        public void run() {
            try {
                System.out.println("BusiThread线程" + Thread.currentThread().getName() + "准备运行....");
                //只有等countDownLatch的计数器为0，也就是其他计数器的线程都执行完了，才能执行
                countDownLatch.await();
                Thread.sleep(1000);
                System.out.println("BusiThread线程" + Thread.currentThread().getName() + "运行完成....");
            } catch (InterruptedException e) {
                e.printStackTrace();}}}
    public static void main(String[] args) {
        new Thread(new Runnable() {
            @Override
            public void run() {
                System.out.println("主线程" + Thread.currentThread().getName() + "开始初始化....");
                countDownLatch.countDown();
            }
        }, "main-2").start();
        new BusiThread().start();
        for (int i = 0; i < 5; i++) {
            new InitThread().start();
        }
        try {
            countDownLatch.await();
            System.out.println("主线程运行结束.......");
        } catch (InterruptedException e) {
            e.printStackTrace();}}}
```

### CyclicBarrier
CyclicBarrier字面意思是栅栏，是多线程中一个重要的类，主要用于线程组内部之间的线程的相互等待问题，初始化的时候传入需要等待的线程数。
作用：让一组线程达到某个屏障被阻塞，一直到组内最后一个线程达到屏障时，屏障开放，所有被阻塞的线程才会继续运行。其中：
> CyclicBarrier(int parties)：初始化定义需要等待的线程数parties。  
CyclicBarrier(int parties, Runnable barrierAction)：当屏障开放的时候，线程barrierAction的任务会执行。

CountDownLatch和CyclicBarrier的区别：
1. countdownlatch放行由第三者控制，CyclicBarrier放行由一组线程本身控制
2. countdownlatch放行条件>=线程数，CyclicBarrier放行条件=线程数
3. CountDownLatch会阻塞主线程，CyclicBarrier不会阻塞主线程，只会阻塞子线程。
4. CountDownLatch的计数器只能使用一次。而CyclicBarrier的计数器可以使用reset()方
法重置。所以CyclicBarrier能处理更为复杂的业务场景，比如如果计算发生错误，可以重置计数器，并让线程们重新执行一次。
```Java
public class CyclicBarrierDemo {
    //定义一个栅栏，在栅栏放行的时候，同时可以运行CollectThread这个线程
    private static CyclicBarrier cyclicBarrier = new CyclicBarrier(5, new CollectThread());
    private static ConcurrentHashMap<Long, String> concurrentHashMap = new ConcurrentHashMap();
    private static class CollectThread extends Thread {
        @Override
        public void run() {
            System.out.println(concurrentHashMap.size());}}
    private static class SubThread extends Thread {
        @Override
        public void run() {
            try {
                Random random = new Random();
                long id = Thread.currentThread().getId();
                String name = Thread.currentThread().getName();
                concurrentHashMap.put(id, name);
                if (random.nextBoolean()) {
                    System.out.println("SubThread线程" + name + "正在处理中....");
                    Thread.sleep(2000);
                }
                System.out.println("SubThread线程" + name + "处理结束，等待其他线程处理结束....");
                //每个子线程都会在这里阻塞，等待所有的子线程都执行到这里，才会一起放行
                cyclicBarrier.await();
                System.out.println("SubThread线程" + name + "处理完毕....");
            } catch (InterruptedException e) {
                e.printStackTrace();
            } catch (Exception e) {
                e.printStackTrace();}}}

    public static void main(String[] args) {
        for (int i = 0; i < 5; i++) {
            new SubThread().start();}
        //CyclicBarrier，不会阻塞主线程
        System.out.println("主线程.....");}}
```
### Semaphore
Semaphore又名信号量，是操作系统中的一个概念，在Java并发编程中，信号量控制的是线程并发的数量。
作用：Semaphore管理一系列许可证。每个acquire方法阻塞，直到有一个许可证可以获得然后拿走一个许可证；每个release方法增加一个许可证，这可能会释放一个阻塞的acquire方法。然而，其实并没有实际的许可证这个对象，Semaphore只是维持了一个可获得许可证的数量，主要控制同时访问某个特定资源的线程数量，多用在流量控制。
注意：其他Semaphore的底层实现就是基于AQS的共享锁实现的。
> 如果一个线程要访问共享资源，必须先获得信号量，如果信号量的计数器值大于1，意味
着有共享资源可以访问，则使其计数器值减去1，再访问共享资源。如果计数器值为0，线
程进入休眠。当某个线程使用完共享资源后，释放信号量，并将信号量内部的计数器加1，之前进入休眠的线程将被唤醒并再次试图获得信号量。

Demo: [SemphoreDemo](https://github.com/xiangzz159/JInterview-demo/blob/master/multithreading/src/main/java/com/mythtrad/proj6/others/TestSemphore.java)

### Exchange
Exchange类似于一个交换器，可以在对中对元素进行配对和交换的线程的同步点，用于两个线程间的数据交换。
具体来说，Exchanger类允许在两个线程之间定义同步点。当两个线程都到达同步点时，他们交换数据结构，因此第一个线程的数据结构进入到第二个线程中，第二个线程的数据结构进入到第一个线程中。
```Java
public class ExchangerDemo {
    private static Exchanger<Set<String>> exchanger = new Exchanger<>();
    private static class ExchangerClassO extends Thread {
        private Set<String> set;
        public ExchangerClassO(Set<String> set) {
            this.set = set;
        }
        @Override
        public void run() {
            try {
                exchange(set);
            } catch (InterruptedException e) {
                e.printStackTrace();}}}
    private static class ExchangerClassT extends Thread {
        private Set<String> set;
        public ExchangerClassT(Set<String> set) {
            this.set = set;}
        @Override
        public void run() {
            try {
                exchange(set);

            } catch (InterruptedException e) {
                e.printStackTrace();}}}
    private static void exchange(Set<String> set) throws InterruptedException {
        //交换数据，阻塞
        System.out.println("线程：" + Thread.currentThread().getName() + "交换前得值....");
        for (String s : set) {
            System.out.println(s);
        }
        exchanger.exchange(set);
        System.out.println("线程：" + Thread.currentThread().getName() + "交换后得值....");
        for (String s : set) {
            System.out.println(s);}}
    public static void main(String[] args) {
        Set<String> setA = new HashSet<>();
        Set<String> setB = new HashSet<>();
        setA.add("a1");
        setA.add("b1");
        setA.add("c1");
        setB.add("a2");
        setB.add("b2");
        setB.add("c2");
        new ExchangerClassO(setA).start();
        new ExchangerClassT(setB).start();}}
```

# 线程池和Executor框架
## 什么是线程池
线程池是指在初始化一个多线程应用程序过程中创建一个线程集合，然后在需要执行新的任务时重用这些线程而不是新建一个线程。线程池中线程的数量通常完全取决于可用内存数量和应用程序的需求。然而，增加可用线程数量是可能的。线程池中的每个线程都有被分配一个任务，一旦任务已经完成了，线程回到池子中并等待下一次分配任务。

## 为什么要使用线程池
因为创建和销毁线程都是需要时间的，特别是需要创建大量线程的时候，时间和资源的消耗是不可忽略的，而合理的使用线程池中已经创建的线程，可以减少创建和销毁线程而花费的时间和资源。

## 线程池的优点
1. 降低资源消耗：通过线程的重用可以降低创建和销毁线程花费的时间和资源；
2. 提高响应速度：任务到达时，因为利用线程池中已经创建好的线程，可以不用等待线程创建而直接执行任务；
3. 提高线程的可管理性：线程池允许我们开启多个任务而不用为每个线程设置属性（便于管理）；线程池根据当前在系统中运行的进程来优化线程时间片（调优）；线程池可以限制创建线程的数量，如果无限制的创建线程，不仅会消耗资源，还会降低系统的稳定性；


## 线程池ThreadPoolExecutor原理与应用
![img](./img/1598528-20191229160719790-405993127.png)

![img](./img/1598528-20191229160754706-127912585.png)

### 线程池的创建和线程池的基本设置：（6个参数）
ThreadPoolExecutor初始化
```Java
ThreadPoolExecutor tpe = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, timeUnit, runnalbleTaskQueue, handler);
```

corePoolSize：核心线程池的大小。如果调用了prestartAllCoreThread（）方法，那么线程池会提前创建并启动所有基本线程。

maximumPoolSize：线程池的大小。

keepAliveTime：闲置时间。线程空闲后，线程存活时间。如果任务多，任务周期短，可以调大keepAliveTime，提高线程利用率。

timeUnit：闲置时间的时间单位。有天（DAYS）、小时(HOURS)、分（MINUTES）、秒（SECONDS）、毫秒（MILLISECONDS）、微秒（MICROSECONDS）、纳秒（NANOSECONDS）

runnalbleTaskQueue：阻塞队列方式。（4种）
- ArrayBlockingQueue
- LinkedBlockingQueue、
- SynchronousQueue、
- PriorityBlockingQueue

静态工厂方法Executors.newFixedThreadPool(  )使用了LinkedBlockingQueue；

静态工厂方法Executors.newCachedThreadPool(  )使用了SynchronousQueue；

handler：饱和策论。（4种）

线程池满了的时候，任务无法得到处理，这时候需要饱和策略来处理无法完成的任务，饱和策略中有4种处理策略：

- AbortPolicy：这是默认的策略，直接抛出异常；
- CallerRunsPolicy：只是用调用者所在线程来运行任务；
- DiscardOldestPolicy：丢弃队列中最老的任务，并执行当前任务；
- DiscardPolicy：不处理，直接把当前任务丢弃；

当然也可以自定义饱和处理策略，需要实现RejectedExecutionHandler接口，比如记录日志或者持久化不能存储的任务等。

### 向线程池提交任务
1. execute用于提交没有返回值的任务，所以无法判断任务是否被线程执行过。
    ```Java
    public class ThreadPoolExecutorDemo1 {
        public static void main(String[] args) {
            //线程池的创建
            ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(5,10 ,
                    100 ,MILLISECONDS,new ArrayBlockingQueue<Runnable>(5));
            //提交线程池任务
            threadPoolExecutor.execute(new Thread(new Runnable() {
                @Override
                public void run() {
                    System.out.println("thread 1 execute work" );
                }
            }));
            //停止线程池
            threadPoolExecutor.shutdown();}}
    ```

2. submit（）：用于提交需要返回值的对象。
   ```Java
    public class ThreadPoolExecutorDemo2 {
        public static void main(String[] args) {
            //线程池的创建
            ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(5, 10,
                    100, MILLISECONDS, new ArrayBlockingQueue<Runnable>(5));
            //添加任务
            Future future= threadPoolExecutor.submit(new Callable<String>() {
                @Override
                public String call() throws Exception {
                    String a ="return call";
                    return a;}});
            try {
                System.out.println(future.get());//future.get()调用call()方法的返回结果
            } catch (InterruptedException | ExecutionException e) {
                e.printStackTrace();
            } finally{
                threadPoolExecutor.shutdown();}}}
   ```







## Executor框架 